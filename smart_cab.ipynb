{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 4: Reinforcement Learning\n",
    "### Train a Smartcab How to Drive\n",
    "<sub>Uirá Caiado. Jul 7, 2016<sub>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Abstract\n",
    "\n",
    "_As pointed out by ..._\n",
    "\n",
    "\n",
    "\n",
    "...agents by reward and punishment without needing to specify how the task is to be achieved. But there are formidable computational obstacles to fulfilling the promise. Reinforcement learning is the problem faced by an agent that must learn behavior through trial-and-error interactions with a dynamic environment.\n",
    "Thishappens in our example above: from state 65, applying action 2 produces di\u000b",
    "ering reinforcements\n",
    "and di\u000b",
    "ering states on two occasions. However, we assume the environment is\n",
    "stationary; that is, that the probabilities of making state transitions or receiving speci\f",
    "c\n",
    "reinforcement signals do not change over time Reinforcement learning di\u000b",
    "ers from the more widely studied problem of supervised learning in several ways. The most important di\u000b",
    "erence is that there is no presentation of input/\n",
    "output pairs. Instead, after choosing an action the agent is told the immediate reward\n",
    "and the subsequent state, but is not told which action would have been in its best long-term\n",
    "interests. It is necessary for the agent to gather useful experience about the possible system\n",
    "states, actions, transitions and rewards actively to act optimally. Another di\u000b",
    "erence from\n",
    "supervised learning is that on-line performance is important: the evaluation of the system\n",
    "is often concurrent with learning.\n",
    "\n",
    "AHC architectures seem to be more di\u000ecult to work with than Q-learning on a practical\n",
    "level. It can be hard to get the relative learning rates right in AHC so that the two\n",
    "components converge together. In addition, Q-learning is exploration insensitive: that\n",
    "is, that the Q values will converge to the optimal values, independent of how the agent\n",
    "behaves while the data is being collected (as long as all state-action pairs are tried often\n",
    "enough). This means that, although the exploration-exploitation issue must be addressed\n",
    "in Q-learning, the details of the exploration strategy will not a\u000b",
    "ect the convergence of the\n",
    "learning algorithm. For these reasons, Q-learning is the most popular and seems to be the\n",
    "most e\u000b",
    "ective model-free algorithm for learning from delayed reinforcement. It does not,\n",
    "however, address any of the issues involved in generalizing over large state and/or action\n",
    "spaces. In addition, it may converge quite slowly to a good policy\n",
    "\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "In this section,\n",
    "\n",
    "### 1.1. Some Background\n",
    "\n",
    "As suggested ...\n",
    "\n",
    "### 1.2. Getting Started\n",
    "\n",
    "The dataset for ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Implement a Basic Driving Agent\n",
    "\n",
    "In this section, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Udacity:\n",
    "\n",
    "It is asked to:\n",
    "\n",
    "- Agent accepts inputs: Student is able to implement the desired interface to the agent that accepts specified inputs.\n",
    "- Produces a valid output: The driving agent produces a valid output (one of None, ‘forward’, ‘left’, ‘right’) in response to the inputs.\n",
    "- Runs in simulator: The driving agent runs in the simulator without errors. Rewards and penalties do not matter - it’s okay for the agent to make mistakes. In your report, mention what you see in the agent’s behavior. Does it eventually make it to the target location?\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Identify and Update State\n",
    "\n",
    "In this section, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Udacity:\n",
    "\n",
    "It is asked to:\n",
    "\n",
    "- Reasonable states identified: Student has identified states that model the driving agent and environment, along with a sound justification. Justify why you picked these set of states, and how they model the agent and its environment.\n",
    "-  Agent updates state: The driving agent updates its state when running, based on current input. The exact state does not matter, and need not be correlated with inputs, but it should change during a run.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Implement Q-Learning\n",
    "\n",
    "In this section, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Udacity:\n",
    "\n",
    "It is asked to:\n",
    "\n",
    "- Agent updates Q-values: The driving agent updates a table/mapping of Q-values correctly, implementing the Q-Learning algorithm.\n",
    "- Picks the best action: Given the current set of Q-values for a state, it picks the best available action.\n",
    "- Changes in behavior explained: Student has reported the changes in behavior observed, and provided a reasonable explanation for them. What changes do you notice in the agent’s behavior?\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Enhance the Driving Agent\n",
    "\n",
    "In this section, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Udacity:\n",
    "\n",
    "It is asked to:\n",
    "\n",
    "- Agent learns a feasible policy within 100 trials: The driving agent is able to consistently reach the destination within allotted time, with net reward remaining positive.\n",
    "- Improvements reported: Specific improvements made by the student beyond the basic Q-Learning implementation have been reported, including at least one parameter that was tuned along with the values tested. The corresponding results for each value are also reported.\n",
    "- Final agent performance discussed: A description is provided of what an ideal or optimal policy would be. The performance of the final driving agent is discussed and compared to how close it is to learning the stated optimal policy. Report what changes you made to your basic implementation of Q-Learning to achieve the final version of the agent. How well does it perform? Does your agent get close to finding an optimal policy, i.e. reach the destination in the minimum possible time, and not incur any penalties?\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusion\n",
    "\n",
    "\n",
    "bla bla bla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Reflection\n",
    "\n",
    "\n",
    "bla bla bla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Style notebook and change matplotlib defaults*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunss.otf');\n",
       "    }\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        font-weight: bold;\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunsx.otf');\n",
       "    }\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        font-style: oblique;\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunsi.otf');\n",
       "    }\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        font-weight: bold;\n",
       "        font-style: oblique;\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunso.otf');\n",
       "    }\n",
       "    div.cell{\n",
       "        width:800px;\n",
       "        margin-left:16% !important;\n",
       "        margin-right:auto;\n",
       "    }\n",
       "    h1 {\n",
       "        font-family: Helvetica, serif;\n",
       "    }\n",
       "    h4{\n",
       "        margin-top:12px;\n",
       "        margin-bottom: 3px;\n",
       "       }\n",
       "    div.text_cell_render{\n",
       "        font-family: Computer Modern, \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;\n",
       "        line-height: 145%;\n",
       "        font-size: 130%;\n",
       "        width:800px;\n",
       "        margin-left:auto;\n",
       "        margin-right:auto;\n",
       "    }\n",
       "    .CodeMirror{\n",
       "            font-family: \"Source Code Pro\", source-code-pro,Consolas, monospace;\n",
       "    }\n",
       "    .prompt{\n",
       "        display: None;\n",
       "    }\n",
       "    .text_cell_render h5 {\n",
       "        font-weight: 300;\n",
       "        font-size: 22pt;\n",
       "        color: #4057A1;\n",
       "        font-style: italic;\n",
       "        margin-bottom: .5em;\n",
       "        margin-top: 0.5em;\n",
       "        display: block;\n",
       "    }\n",
       "\n",
       "    .warning{\n",
       "        color: rgb( 240, 20, 20 )\n",
       "        }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "<style>\n",
       "    table {\n",
       "        overflow:hidden;\n",
       "        font-family: Computer Modern, \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;\n",
       "        font-size: 12px;\n",
       "        margin: 10px;\n",
       "        width: 480px;\n",
       "        text-align: left;\n",
       "        border-collapse: collapse;\n",
       "        border: 1px solid #d3d3d3;\n",
       "        -moz-border-radius:5px; FF1+;\n",
       "        -webkit-border-radius:5px; Saf3-4;\n",
       "        border-radius:5px;\n",
       "        -moz-box-shadow: 0 0 4px rgba(0, 0, 0, 0.01);\n",
       "    }\n",
       "    th\n",
       "    {\n",
       "        padding: 12px 17px 12px 17px;\n",
       "        font-weight: normal;\n",
       "        font-size: 14px;\n",
       "        border-bottom: 1px dashed #69c;\n",
       "    }\n",
       "\n",
       "    td\n",
       "    {\n",
       "        padding: 7px 17px 7px 17px;\n",
       "\n",
       "    }\n",
       "\n",
       "    tbody tr:hover th\n",
       "    {\n",
       "\n",
       "        background:  #E9E9E9;\n",
       "    }\n",
       "\n",
       "    tbody tr:hover td\n",
       "    {\n",
       "\n",
       "        background:  #E9E9E9;\n",
       "    }\n",
       "\n",
       "</style>\n",
       "\n",
       "<script>\n",
       "    MathJax.Hub.Config({\n",
       "                        TeX: {\n",
       "                           extensions: [\"AMSmath.js\"]\n",
       "                           },\n",
       "                tex2jax: {\n",
       "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
       "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
       "                },\n",
       "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
       "                \"HTML-CSS\": {\n",
       "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
       "                }\n",
       "        });\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading style sheet\n",
    "from IPython.core.display import HTML\n",
    "HTML( open('ipython_style.css').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#changing matplotlib defaults\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_palette(\"deep\", desat=.6)\n",
    "sns.set_context(rc={\"figure.figsize\": (8, 4)})\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(sns.color_palette(\"Set2\", 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
